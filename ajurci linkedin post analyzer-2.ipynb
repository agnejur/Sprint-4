{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObEgdhdz8bk/OBpMwEoaMx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6f8fbcbdc4604d2fbdd66f01911ba41e":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"Post:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_babeddb87ba941a28757ee1776487483","placeholder":"Paste your LinkedIn post here...","rows":null,"style":"IPY_MODEL_0294ab6440cb471d8e59fd4dc2fa480c","value":"The Leadership Crisis: Not a Lack of Ideas, but a Lack of Leaders \n\nToday, I had the pleasure of speaking at the \"Pardavim≈≥ formulƒó\" conference alongside Vladas Korsakovas, the founder of Sportland, moderated by Saulius Jovaisas. \nIn a thought-provoking discussion we tackled a challenging question: Is the crisis due to a lack of creativity, or is it a deeper issue‚Äîa crisis of courage, clarity, and accountability?\n\nI shared a simple observation: sales is storytelling. We're all in sales. We're selling as soon as we understand who we are and what we want. Think of a two-year-old persuading her parents for another scoop of ice cream. There‚Äôs pure passion, persistence, and a genuine belief in what they want. That is the essence of sales‚Äîan authentic story, unfiltered and driven by conviction. If we approached every sales pitch with that same clarity and enthusiasm, the results would be transformative.\n\nüîé True leadership in sales is about unlocking potential, seeing the cathedral in the building process while the others only see bricks laying, and inspiring teams to believe in the story they are telling.\nIn our discussion, we challenged the conventional understanding of leadership. What if the problem isn‚Äôt that we don‚Äôt have enough leaders‚Äîbut that we misunderstand what true leadership looks like? It‚Äôs not just about breaking through walls with brute force; it‚Äôs about building trust, narrating powerful stories, and turning vision into reality.\n\nA big thank you to the organizers for creating an engaging platform to share ideas and challenge the status quo in leadership today."}},"babeddb87ba941a28757ee1776487483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"250px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0294ab6440cb471d8e59fd4dc2fa480c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75e69d8c60194ce0bff6e0279c813264":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"primary","description":"Analyze Post","disabled":false,"icon":"","layout":"IPY_MODEL_b99d98966ea14fc68e35a80bd6ccae5d","style":"IPY_MODEL_4dd6addcb8fb4780ba3a7e5805f92559","tooltip":"Click to analyze the LinkedIn post"}},"b99d98966ea14fc68e35a80bd6ccae5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dd6addcb8fb4780ba3a7e5805f92559":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"ff58658c441441b788d3a251bbf6dadb":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_17f5f237e9584a529405d393e23a5f20","msg_id":"","outputs":[{"output_type":"stream","name":"stdout","text":["üîé Analyzing LinkedIn Post...\n","\n","=== üõ†Ô∏è Preprocessing ===\n","‚Ä¢ Words: 258\n","‚Ä¢ Characters: 1600\n","‚Ä¢ Length Feedback: Length is appropriate.\n","‚Ä¢ Grammar: Grammar corrected using GPT.\n","\n","=== üßπ Cleaned Post (Corrected) ===\n","None\n","\n","=== ü§ñ GPT Analysis ===\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'analyze_linkedin_post' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0c2566a04d76>\u001b[0m in \u001b[0;36mon_analyze_clicked\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== ü§ñ GPT Analysis ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_linkedin_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corrected\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"raw\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'analyze_linkedin_post' is not defined"]}]}},"17f5f237e9584a529405d393e23a5f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98dd61aa34d042518efbd153fa454a45":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"Post:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_3de6419aa20d4d0893573800bbddedb9","placeholder":"Paste your LinkedIn post here...","rows":null,"style":"IPY_MODEL_874ee1947c49491e93986cee1c301876","value":"Paste your LinkedIn post here..."}},"3de6419aa20d4d0893573800bbddedb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"250px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"874ee1947c49491e93986cee1c301876":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1f17765eb4543ac93cf3c75a5dc95a3":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"primary","description":"Analyze Post","disabled":false,"icon":"","layout":"IPY_MODEL_fc1ca417b155429f8f9d03d7285c829e","style":"IPY_MODEL_8a6e43ea0128460296b62cef92d0246a","tooltip":"Click to analyze the LinkedIn post"}},"fc1ca417b155429f8f9d03d7285c829e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a6e43ea0128460296b62cef92d0246a":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"df28f61a9f364757bd225566f84c874c":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_72c6853573734c498c40f9bd14a19475","msg_id":"","outputs":[]}},"72c6853573734c498c40f9bd14a19475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ac48c68e30c4548b1599da865af320a":{"model_module":"@jupyter-widgets/controls","model_name":"TextareaModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"Post:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_799902f4933d42b6bed9b17f770eab41","placeholder":"Paste your LinkedIn post here...","rows":null,"style":"IPY_MODEL_e551071b132143e38e96bbaf4a239da0","value":"Paper piles, lost files, and endless delays‚Ä¶ it‚Äôs time to be honest üëá\nWhat‚Äôs the WORST thing about managing paper files?\n\nWe want to know what frustrates you the most when dealing with paper-based processes. Vote below and see how others feel too!\n\nüí° Explore our Paperless Solutions and say goodbye to the paper chaos: https://lnkd.in/dpAiYUSF\n\nhashtag#InformationManagement hashtag#DigitalTransformation hashtag#PaperlessOffice hashtag#CrownInformat"}},"799902f4933d42b6bed9b17f770eab41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"250px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e551071b132143e38e96bbaf4a239da0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b28edbb745cc464096bd256335ef1cb9":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"primary","description":"Analyze Post","disabled":false,"icon":"","layout":"IPY_MODEL_37f40f5241a54d0da42b096583a1b7b5","style":"IPY_MODEL_92c827b98469441bb22835ceb4d343df","tooltip":"Click to analyze the LinkedIn post"}},"37f40f5241a54d0da42b096583a1b7b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92c827b98469441bb22835ceb4d343df":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"635e36cb13d14e54b5238cd5d9fa777c":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_b3df0dc1eebe404ea4c6b8f1c7b1c71f","msg_id":"","outputs":[{"output_type":"stream","name":"stdout","text":["üîé Analyzing LinkedIn Post...\n","\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'correct_grammar_with_gpt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-0c2566a04d76>\u001b[0m in \u001b[0;36mon_analyze_clicked\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mraw_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpost_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_linkedin_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== üõ†Ô∏è Preprocessing ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-b27da7505b8c>\u001b[0m in \u001b[0;36mpreprocess_linkedin_post\u001b[0;34m(raw_post)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlength_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Length is appropriate.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_grammar_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcorrection_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Grammar corrected using GPT.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'correct_grammar_with_gpt' is not defined"]}]}},"b3df0dc1eebe404ea4c6b8f1c7b1c71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6w2NvFhCI-g","executionInfo":{"status":"ok","timestamp":1747045708547,"user_tz":-180,"elapsed":11237,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"35346e2a-894c-40c6-fae0-f850638b5785"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n","Collecting openai\n","  Downloading openai-1.78.1-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n","Downloading openai-1.78.1-py3-none-any.whl (680 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m680.9/680.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.76.2\n","    Uninstalling openai-1.76.2:\n","      Successfully uninstalled openai-1.76.2\n","Successfully installed openai-1.78.1\n"]}],"source":["!pip install --upgrade openai\n"]},{"cell_type":"code","source":["from getpass import getpass\n","import os\n","\n","# Securely enter your API key\n","os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîê Enter your OpenAI API key: \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHf8_4-MCe32","executionInfo":{"status":"ok","timestamp":1747045743503,"user_tz":-180,"elapsed":13205,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"cd3c9cea-4a2f-4801-c917-7b327bf78fc2"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["üîê Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","# Create a client using the secure API key\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"],"metadata":{"id":"1QGoXB0ICp02","executionInfo":{"status":"error","timestamp":1747068249703,"user_tz":-180,"elapsed":1773,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"colab":{"base_uri":"https://localhost:8080/","height":176},"outputId":"1113f0b7-5e1b-4eed-c9c6-a91179537ef3"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8462292c96a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a client using the secure API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["def analyze_linkedin_post(post_text: str) -> dict:\n","    \"\"\"\n","    Sends a LinkedIn post to ChatGPT and returns a dict with:\n","      - engagement: str\n","      - user_value: str\n","      - suggestions: str\n","    \"\"\"\n","    system_prompt = (\n","        \"You are an expert content analyst. \"\n","        \"Given a LinkedIn post, provide:\\n\"\n","        \"1. Engagement: is the post likely engaging? Why/why not?\\n\"\n","        \"2. User-value: what actionable or informational value does it offer?\\n\"\n","        \"3. Suggestions: how to improve engagement or clarity.\\n\"\n","        \"Return your answer in JSON with keys 'engagement', 'user_value', 'suggestions'.\"\n","    )\n","\n","    user_prompt = f\"LinkedIn post:\\n\\\"\\\"\\\"\\n{post_text}\\n\\\"\\\"\\\"\"\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o\",  # or use gpt-3.5-turbo\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt},\n","            {\"role\": \"user\", \"content\": user_prompt}\n","        ],\n","        temperature=0.3,\n","    )\n","\n","    import json\n","    reply = response.choices[0].message.content\n","    try:\n","        return json.loads(reply)\n","    except json.JSONDecodeError:\n","        return {\"raw\": reply}\n"],"metadata":{"id":"LgX_oXUUCx-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    print(\"üîé LinkedIn Post Analyzer\")\n","    post = input(\"Enter your LinkedIn post text:\\n> \")\n","    result = analyze_linkedin_post(post)\n","\n","    print(\"\\n=== Analysis Result ===\")\n","    if \"raw\" in result:\n","        print(result[\"raw\"])\n","    else:\n","        print(f\"‚Ä¢ Engagement: {result['engagement']}\")\n","        print(f\"‚Ä¢ User Value: {result['user_value']}\")\n","        print(f\"‚Ä¢ Suggestions: {result['suggestions']}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XOkYLVfC3gW","executionInfo":{"status":"ok","timestamp":1747045834028,"user_tz":-180,"elapsed":22934,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"a8bf1938-c7b9-46f0-9e20-990173509310"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîé LinkedIn Post Analyzer\n","Enter your LinkedIn post text:\n","> One of the most polluting and most negative types of waste on the environment is hashtag#automobilinƒós hashtag#atliekos. The management of end-of-life lead batteries, car filters, shock absorbers, used oil, hazardous liquids and other automotive waste, and especially their recycling, requires specific knowledge, infrastructure and financing.    üîù Over the course of 35 years, the management of automotive waste in Lithuania has come a long way ‚Äì from the creation of a legal framework for the collection and management of this waste, to the establishment of management tasks and responsibilities for placing products on the market.    üîõ Today, we have an efficient system. The collection of waste from the main categories of taxable products ‚Äì lead batteries, tyres, filters, shock absorbers ‚Äì reaches an average of 94-100% per year.  üìå The exception and problem is hashtag#alyva. Around 30 000 tonnes of oil enter the domestic market every year, but the collection of waste oil is only 40% of the annual amount imported.   The achievements and challenges of automotive waste management were shared hashtag#Atliekos by ≈ΩALVARIS Commercial Director Kristina Kavaliauskiene at the practical conference. According to her, in order to solve the problem of oil waste management, bold solutions are necessary: the return of the responsibility of producers and importers, the tax for environmental pollution, and greater control of the accounting of waste companies engaged in car repair activities.   We have to recognise that honesty costs more. However, this is the only way we can collectively take responsibility for the negative impact of our own activities on the environment.    üì∏ hashtag#AtliekosPraktinƒóKonferencija   hashtag#AutomobilinesAtliekos hashtag#AtliekuTvarkymas hashtag#AlyvosAtliekos hashtag#PoveikisAplinkai hashtag#Pavoji\n","\n","=== Analysis Result ===\n","```json\n","{\n","  \"engagement\": \"The post is likely to be moderately engaging. It discusses a relevant environmental issue, which can attract professionals in the waste management and automotive industries. However, the use of hashtags in the middle of sentences can disrupt the reading flow, and the post is quite dense with information, which might deter some readers.\",\n","  \"user_value\": \"The post provides informational value by highlighting the achievements and challenges in automotive waste management in Lithuania. It offers insights into the current state of waste management systems and suggests potential solutions for improving oil waste management. This can be valuable for professionals in environmental policy, waste management, and automotive industries.\",\n","  \"suggestions\": \"To improve engagement and clarity, consider the following: 1. Move hashtags to the end of the post to enhance readability. 2. Break down the dense information into bullet points or shorter paragraphs to make it more digestible. 3. Include a call-to-action or question to encourage interaction, such as asking readers for their thoughts on improving waste management systems.\"\n","}\n","```\n"]}]},{"cell_type":"code","source":["system_prompt = (\n","    \"You are a professional content analyst with expertise in business information security, data governance, and records management. \"\n","    \"Your task is to analyze a LinkedIn post relevant to this field and provide:\\n\\n\"\n","    \"1. Engagement: Is the post likely to attract attention within professional circles? Does it prompt reactions, comments, or shares?\\n\"\n","    \"2. User-value: What value does it provide to professionals in information security, compliance, digital archiving, or document lifecycle management?\\n\"\n","    \"3. Suggestions: What could improve its impact ‚Äî such as clarity, authority, call to action, or format?\\n\\n\"\n","    \"Respond in a JSON format with three keys: 'engagement', 'user_value', and 'suggestions'.\"\n",")\n"],"metadata":{"id":"lEpEWh94E72A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate_post_structure(post_text: str) -> dict:\n","    \"\"\"\n","    Validates the structure and length of a LinkedIn post.\n","    Returns feedback on:\n","    - word count\n","    - character count\n","    - paragraph use\n","    - presence of hashtags\n","    - presence of a likely call-to-action\n","    \"\"\"\n","    feedback = {}\n","\n","    word_count = len(post_text.split())\n","    char_count = len(post_text)\n","    paragraphs = post_text.count('\\n') + 1\n","    hashtags = [word for word in post_text.split() if word.startswith('#') or 'hashtag#' in word]\n","    has_cta = any(phrase in post_text.lower() for phrase in [\n","        \"read more\", \"contact us\", \"get in touch\", \"visit our site\", \"learn more\", \"register\", \"join\", \"download\"\n","    ])\n","\n","    # Assess length\n","    if word_count < 30:\n","        feedback['length'] = \"Post may be too short to be informative or engaging.\"\n","    elif word_count > 300:\n","        feedback['length'] = \"Post may be too long; consider shortening for better engagement.\"\n","    else:\n","        feedback['length'] = \"Length is within a typical and effective range.\"\n","\n","    # Paragraphs\n","    if paragraphs < 2:\n","        feedback['paragraphs'] = \"Consider breaking content into 2 or more paragraphs for readability.\"\n","    else:\n","        feedback['paragraphs'] = \"Paragraph structure looks appropriate.\"\n","\n","    # Hashtags\n","    if not hashtags:\n","        feedback['hashtags'] = \"Consider adding relevant hashtags to improve discoverability.\"\n","    else:\n","        feedback['hashtags'] = f\"{len(hashtags)} hashtag(s) detected.\"\n","\n","    # Call-to-action\n","    if not has_cta:\n","        feedback['call_to_action'] = \"No call-to-action detected. Consider adding one to drive engagement.\"\n","    else:\n","        feedback['call_to_action'] = \"Call-to-action detected.\"\n","\n","    # Summary stats\n","    feedback['word_count'] = word_count\n","    feedback['char_count'] = char_count\n","\n","    return feedback\n"],"metadata":{"id":"2A3PYHU0FX_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    print(\"üîé LinkedIn Post Analyzer\")\n","    post = input(\"Enter your LinkedIn post text:\\n> \")\n","\n","    # Structural validation\n","    print(\"\\n=== ‚úÖ Pre-check: Structure & Length ===\")\n","    structure_feedback = validate_post_structure(post)\n","    for key, value in structure_feedback.items():\n","        print(f\"{key.capitalize()}: {value}\")\n","\n","    # GPT-based semantic analysis\n","    print(\"\\n=== ü§ñ GPT Semantic Analysis ===\")\n","    result = analyze_linkedin_post(post)\n","    if \"raw\" in result:\n","        print(result[\"raw\"])\n","    else:\n","        print(f\"‚Ä¢ Engagement: {result['engagement']}\")\n","        print(f\"‚Ä¢ User Value: {result['user_value']}\")\n","        print(f\"‚Ä¢ Suggestions: {result['suggestions']}\")\n"],"metadata":{"id":"HbpblVWNFZtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["post = input(\"Enter your LinkedIn post text:\\n> \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"1xaWxZ6OGGlA","executionInfo":{"status":"error","timestamp":1747049276884,"user_tz":-180,"elapsed":1005855,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"54e33c0a-d4a8-4b01-ace9-6128fb8b6801"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-5a74b44ee7e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your LinkedIn post text:\\n> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ic63XvohGy4E","executionInfo":{"status":"ok","timestamp":1747046856395,"user_tz":-180,"elapsed":16144,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"2fd52205-0ad8-42dc-ed10-737c14f92d15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîé LinkedIn Post Analyzer\n","Enter your LinkedIn post text:\n","> üì£ Exciting News from Polar Imaging!  We're proud to introduce our newest solution: Accessibility on Demand ‚Äì a dedicated platform designed to help organizations meet AODA and WCAG 2.0 Level AA compliance quickly and efficiently.  Accessibility on Demand is the first truly automated PDF accessibility platform that remediates documents in minutes without technical expertise. Most tools on the market still require heavy manual work and trained specialists, but AOD changes that completely.  Here‚Äôs what makes it stand out: üî∏ Automates up to 95% of the remediation process - no more tagging PDFs by hand üî∏ Scalable & lightning fast - remediate thousands of pages in minutes üî∏ WCAG & PDF/UA compliant - includes third-party compliance validation üî∏ Canadian-ready - aligns with AODA/ACA mandates and supports data residency needs  üîó Read our blog post: https://lnkd.in/exNQuUVY üîó Read the full Accessibility on Demand Overview: https://lnkd.in/evJEseYi  hashtag#AODA hashtag#PDFCompliance hashtag#DigitalAccessibility hashtag#DocumentManagement hashtag#PolarIm\n","\n","=== ‚úÖ Pre-check: Structure & Length ===\n","Length: Length is within a typical and effective range.\n","Paragraphs: Consider breaking content into 2 or more paragraphs for readability.\n","Hashtags: 5 hashtag(s) detected.\n","Call_to_action: No call-to-action detected. Consider adding one to drive engagement.\n","Word_count: 148\n","Char_count: 1058\n","\n","=== ü§ñ GPT Semantic Analysis ===\n","```json\n","{\n","  \"engagement\": \"The post is likely engaging due to its announcement of a new product that addresses a specific need in the market. It uses strong, attention-grabbing language and provides clear benefits of the product. The inclusion of hashtags and links encourages interaction and further exploration.\",\n","  \"user_value\": \"The post offers significant informational value by introducing a new solution for PDF accessibility compliance, which is a critical need for many organizations. It highlights the efficiency and compliance benefits, which can be actionable for businesses looking to streamline their document management processes.\",\n","  \"suggestions\": \"To improve engagement, the post could include a call-to-action encouraging users to comment or share their experiences with document accessibility challenges. Adding a brief customer testimonial or case study could also enhance credibility and interest. Additionally, breaking down the text with bullet points or emojis could improve readability.\"\n","}\n","```\n"]}]},{"cell_type":"code","source":["import re\n","\n","def validate_openai_api_key(key: str) -> bool:\n","    \"\"\"\n","    Checks if the OpenAI API key format is correct.\n","    Must start with 'sk-' and be followed by 48+ alphanumeric characters.\n","    \"\"\"\n","    pattern = r\"^sk-[A-Za-z0-9]{48,}$\"\n","    return bool(re.match(pattern, key))\n"],"metadata":{"id":"mBMFJ-BCIEzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from getpass import getpass\n","import os\n","import re\n","\n","# Securely enter key\n","api_key = getpass(\"üîê Enter your OpenAI API key: \")\n","\n","# Validate format\n","def validate_openai_api_key(key: str) -> bool:\n","    pattern = r\"^sk-[A-Za-z0-9]{48,}$\"\n","    return bool(re.match(pattern, key))\n","\n","if validate_openai_api_key(api_key):\n","    os.environ[\"OPENAI_API_KEY\"] = api_key\n","    print(\"‚úÖ API key format is valid.\")\n","else:\n","    print(\"‚ùå Invalid API key format. Please re-check and enter again.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8turdzjISH8","executionInfo":{"status":"ok","timestamp":1747047268702,"user_tz":-180,"elapsed":13387,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"2b6634ff-445a-4631-9e36-79ccd925fe58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîê Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n","‚ùå Invalid API key format. Please re-check and enter again.\n"]}]},{"cell_type":"code","source":["api_key = getpass(\"üîê Enter your OpenAI API key: \").strip()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5suQRLVIvyv","executionInfo":{"status":"ok","timestamp":1747047366622,"user_tz":-180,"elapsed":11999,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"584cbf9f-82b4-44d9-bb86-15608083bc41"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["üîê Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["!pip install language-tool-python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTQFAWbPKbUX","executionInfo":{"status":"ok","timestamp":1747047796684,"user_tz":-180,"elapsed":3358,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"0c1d6465-9649-4dcb-cf23-4c9767c36750"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting language-tool-python\n","  Downloading language_tool_python-2.9.3-py3-none-any.whl.metadata (54 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/54.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n","Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.4.26)\n","Downloading language_tool_python-2.9.3-py3-none-any.whl (55 kB)\n","\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/55.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: language-tool-python\n","Successfully installed language-tool-python-2.9.3\n"]}]},{"cell_type":"code","source":["import re\n","import language_tool_python\n","\n","tool = language_tool_python.LanguageTool('en-US')\n","\n","def preprocess_linkedin_post(raw_post: str) -> dict:\n","    \"\"\"\n","    Processes a LinkedIn post before GPT analysis:\n","    1. Fixes formatting: paragraphs, bullets, hashtags\n","    2. Counts words and characters\n","    3. Applies light grammar correction\n","    Returns:\n","      {\n","        'formatted': cleaned and formatted post (str),\n","        'corrected': grammar-corrected version (str),\n","        'word_count': int,\n","        'char_count': int,\n","        'notes': {length_comment, corrections_applied}\n","      }\n","    \"\"\"\n","\n","    # --- Step 1: Formatting ---\n","    paragraphs = [p.strip() for p in raw_post.strip().split('\\n') if p.strip()]\n","    formatted = \"\\n\\n\".join(paragraphs)\n","    formatted = re.sub(r\"[-‚Ä¢‚û§‚óæ‚ñ™]+ ?\", \"‚Ä¢ \", formatted)             # Normalize bullets\n","    formatted = re.sub(r'\\bhashtag#', '#', formatted)              # Fix old hashtags\n","\n","    # --- Step 2: Word/char stats ---\n","    word_count = len(formatted.split())\n","    char_count = len(formatted)\n","\n","    if word_count < 30:\n","        length_comment = \"Too short ‚Äî consider expanding the post for impact.\"\n","    elif word_count > 300:\n","        length_comment = \"Too long ‚Äî may reduce engagement. Consider trimming.\"\n","    else:\n","        length_comment = \"Length is appropriate.\"\n","\n","    # --- Step 3: Grammar correction ---\n","    matches = tool.check(formatted)\n","    corrected = language_tool_python.utils.correct(formatted, matches)\n","    correction_comment = f\"{len(matches)} grammar suggestion(s) applied.\" if matches else \"No grammar issues found.\"\n","\n","    return {\n","        \"formatted\": formatted,\n","        \"corrected\": corrected,\n","        \"word_count\": word_count,\n","        \"char_count\": char_count,\n","        \"notes\": {\n","            \"length_comment\": length_comment,\n","            \"corrections_applied\": correction_comment\n","        }\n","    }\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"3XVeVUe9KeA2","executionInfo":{"status":"error","timestamp":1747047854918,"user_tz":-180,"elapsed":826,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"94969f75-c200-440c-e209-547dfed03e3b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SystemError","evalue":"Detected java 11.0. LanguageTool requires Java >= 17 for version latest.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a7308fe419a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguage_tool_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_tool_python\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLanguageTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_linkedin_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_post\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, motherTongue, remote_server, newSpellings, new_spellings_persist, host, config, language_tool_download_version)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server_is_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_consume_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_server_on_free_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m_start_server_on_free_port\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'http://{self._host}:{self._port}/v2/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_local_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/server.py\u001b[0m in \u001b[0;36m_start_local_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[1;32m    538\u001b[0m         \u001b[0;31m# Before starting local server, download language tool if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mdownload_lt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_tool_download_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/download_lt.py\u001b[0m in \u001b[0;36mdownload_lt\u001b[0;34m(language_tool_version)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \"\"\"\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mconfirm_java_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_tool_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mdownload_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_tool_download_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/language_tool_python/download_lt.py\u001b[0m in \u001b[0;36mconfirm_java_compatibility\u001b[0;34m(language_tool_version)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmajor_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mminor_version\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmajor_version\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmajor_version\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Detected java {major_version}.{minor_version}. LanguageTool requires Java >= 17 for version {language_tool_version}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemError\u001b[0m: Detected java 11.0. LanguageTool requires Java >= 17 for version latest."]}]},{"cell_type":"code","source":["!pip install gingerit\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eu_T3QAfLBM_","executionInfo":{"status":"ok","timestamp":1747047954607,"user_tz":-180,"elapsed":5050,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"81b2921c-cb9a-4f85-8afe-f104404381cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gingerit\n","  Downloading gingerit-0.0.0.1.tar.gz (966 bytes)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: gingerit\n","  Building wheel for gingerit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gingerit: filename=gingerit-0.0.0.1-py3-none-any.whl size=1305 sha256=3c3f20568654066569dd180bfd6be2fdc8396f68b4d187a7499a9e4689767111\n","  Stored in directory: /root/.cache/pip/wheels/94/4d/e8/4e9e60cc5892b405032e3d0f044da1f757240e945b4fd5c100\n","Successfully built gingerit\n","Installing collected packages: gingerit\n","Successfully installed gingerit-0.0.0.1\n"]}]},{"cell_type":"code","source":["from gingerit.gingerit import GingerIt\n","\n","def correct_grammar(text):\n","    parser = GingerIt()\n","    try:\n","        result = parser.parse(text)\n","        return result['result'], len(result['corrections'])\n","    except Exception as e:\n","        print(\"‚ö†Ô∏è Grammar correction failed:\", e)\n","        return text, 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"rhVOFIXmLFTi","executionInfo":{"status":"error","timestamp":1747048067504,"user_tz":-180,"elapsed":59,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"5efa4d07-3ce9-495c-b1cd-3954dd8285b9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'gingerit.gingerit'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c1fdfd7f0dec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgingerit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgingerit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGingerIt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcorrect_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGingerIt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gingerit.gingerit'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!pip install gingerit==0.8.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27nLpt78Lo3A","executionInfo":{"status":"ok","timestamp":1747048112177,"user_tz":-180,"elapsed":1511,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"f01203df-87e2-4d6c-f69f-04f34fd02382"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement gingerit==0.8.0 (from versions: 0.0.0.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for gingerit==0.8.0\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["def correct_grammar_with_gpt(text: str) -> str:\n","    \"\"\"\n","    Uses GPT to correct grammar, spelling, and structure in a LinkedIn post.\n","    Returns the improved text.\n","    \"\"\"\n","    grammar_prompt = (\n","        \"You are an assistant specialized in professional writing. \"\n","        \"Please correct the grammar, punctuation, and clarity of the following LinkedIn post. \"\n","        \"Do not add or remove content. Only make corrections:\\n\\n\"\n","        f\"{text}\"\n","    )\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o\",  # or \"gpt-3.5-turbo\"\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a grammar corrector.\"},\n","            {\"role\": \"user\", \"content\": grammar_prompt}\n","        ],\n","        temperature=0.2,\n","    )\n","\n","    return response.choices[0].message.content.strip()\n"],"metadata":{"id":"aPa2ENThL1tA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Step 3: Grammar correction using GPT ---\n","corrected = correct_grammar_with_gpt(formatted)\n","correction_comment = \"Grammar corrected using GPT.\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"LySMBhdyL58z","executionInfo":{"status":"error","timestamp":1747048181594,"user_tz":-180,"elapsed":22,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"250dd80d-c80c-40a3-fca8-e6230f0ebd9d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'formatted' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-7936b852bac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Step 3: Grammar correction using GPT ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_grammar_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorrection_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Grammar corrected using GPT.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'formatted' is not defined"]}]},{"cell_type":"code","source":["def preprocess_linkedin_post(raw_post: str) -> dict:\n","    \"\"\"\n","    Processes a LinkedIn post before GPT analysis:\n","    1. Fixes formatting: paragraphs, bullets, hashtags\n","    2. Counts words and characters\n","    3. Applies grammar correction using GPT\n","    Returns:\n","      {\n","        'formatted': cleaned and formatted post (str),\n","        'corrected': grammar-corrected version (str),\n","        'word_count': int,\n","        'char_count': int,\n","        'notes': {length_comment, corrections_applied}\n","      }\n","    \"\"\"\n","\n","    # --- Step 1: Clean format ---\n","    import re\n","    paragraphs = [p.strip() for p in raw_post.strip().split('\\n') if p.strip()]\n","    formatted = \"\\n\\n\".join(paragraphs)\n","    formatted = re.sub(r\"[-‚Ä¢‚û§‚óæ‚ñ™]+ ?\", \"‚Ä¢ \", formatted)\n","    formatted = re.sub(r'\\bhashtag#', '#', formatted)\n","\n","    # --- Step 2: Word/char count ---\n","    word_count = len(formatted.split())\n","    char_count = len(formatted)\n","\n","    if word_count < 30:\n","        length_comment = \"Too short ‚Äî consider expanding the post for impact.\"\n","    elif word_count > 300:\n","        length_comment = \"Too long ‚Äî may reduce engagement. Consider trimming.\"\n","    else:\n","        length_comment = \"Length is appropriate.\"\n","\n","    # --- Step 3: Grammar correction using GPT ---\n","    corrected = correct_grammar_with_gpt(formatted)\n","    correction_comment = \"Grammar corrected using GPT.\"\n","\n","    return {\n","        \"formatted\": formatted,\n","        \"corrected\": corrected,\n","        \"word_count\": word_count,\n","        \"char_count\": char_count,\n","        \"notes\": {\n","            \"length_comment\": length_comment,\n","            \"corrections_applied\": correction_comment\n","        }\n","    }\n"],"metadata":{"id":"U_wCCUqXMKZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_linkedin_post(raw_post: str) -> dict:\n","    # paragraph spacing, bullet normalization, hashtags...\n","    # word/char count\n","    # grammar correction using correct_grammar_with_gpt()\n","    return {\n","        ...\n","    }\n"],"metadata":{"id":"0mBUpS6lULBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def correct_grammar_with_gpt(text: str) -> str:\n","    ...\n"],"metadata":{"id":"7XYKnYGoUMbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def preprocess_linkedin_post(raw_post: str) -> dict:\n","    \"\"\"\n","    Cleans a LinkedIn post:\n","    - Formats spacing, bullets, hashtags\n","    - Counts words/characters\n","    - Fixes grammar using GPT\n","    \"\"\"\n","\n","    # --- Step 1: Format text ---\n","    paragraphs = [p.strip() for p in raw_post.strip().split('\\n') if p.strip()]\n","    formatted = \"\\n\\n\".join(paragraphs)\n","    formatted = re.sub(r\"[-‚Ä¢‚û§‚óæ‚ñ™]+ ?\", \"‚Ä¢ \", formatted)\n","    formatted = re.sub(r'\\bhashtag#', '#', formatted)\n","\n","    # --- Step 2: Length checks ---\n","    word_count = len(formatted.split())\n","    char_count = len(formatted)\n","\n","    if word_count < 30:\n","        length_comment = \"Too short ‚Äî consider expanding the post for impact.\"\n","    elif word_count > 300:\n","        length_comment = \"Too long ‚Äî may reduce engagement. Consider trimming.\"\n","    else:\n","        length_comment = \"Length is appropriate.\"\n","\n","    # --- Step 3: Grammar correction with GPT ---\n","    corrected = correct_grammar_with_gpt(formatted)\n","    correction_comment = \"Grammar corrected using GPT.\"\n","\n","    # --- Step 4: Return result as a dictionary ---\n","    return {\n","        \"formatted\": formatted,\n","        \"corrected\": corrected,\n","        \"word_count\": word_count,\n","        \"char_count\": char_count,\n","        \"notes\": {\n","            \"length_comment\": length_comment,\n","            \"corrections_applied\": correction_comment\n","        }\n","    }\n"],"metadata":{"id":"ZZPi_wZUVGrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","\n","# Create widgets\n","post_input = widgets.Textarea(\n","    value='Paste your LinkedIn post here...',\n","    placeholder='Paste your LinkedIn post here...',\n","    description='Post:',\n","    layout=widgets.Layout(width='100%', height='250px')\n",")\n","\n","analyze_button = widgets.Button(\n","    description='Analyze Post',\n","    button_style='primary',\n","    tooltip='Click to analyze the LinkedIn post'\n",")\n","\n","output = widgets.Output()\n","\n","# Define behavior on click\n","def on_analyze_clicked(b):\n","    with output:\n","        clear_output()\n","        print(\"üîé Analyzing LinkedIn Post...\\n\")\n","\n","        raw_post = post_input.value\n","        post_data = preprocess_linkedin_post(raw_post)\n","\n","        print(\"=== üõ†Ô∏è Preprocessing ===\")\n","        print(f\"‚Ä¢ Words: {post_data['word_count']}\")\n","        print(f\"‚Ä¢ Characters: {post_data['char_count']}\")\n","        print(f\"‚Ä¢ Length Feedback: {post_data['notes']['length_comment']}\")\n","        print(f\"‚Ä¢ Grammar: {post_data['notes']['corrections_applied']}\\n\")\n","\n","        print(\"=== üßπ Cleaned Post (Corrected) ===\")\n","        print(post_data['corrected'])\n","\n","        print(\"\\n=== ü§ñ GPT Analysis ===\")\n","        result = analyze_linkedin_post(post_data[\"corrected\"])\n","        if \"raw\" in result:\n","            print(result[\"raw\"])\n","        else:\n","            print(f\"‚Ä¢ Engagement: {result['engagement']}\")\n","            print(f\"‚Ä¢ User Value: {result['user_value']}\")\n","            print(f\"‚Ä¢ Suggestions: {result['suggestions']}\")\n","\n","# Connect button to function\n","analyze_button.on_click(on_analyze_clicked)\n","\n","# Display interface\n","display(post_input, analyze_button, output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725,"referenced_widgets":["6f8fbcbdc4604d2fbdd66f01911ba41e","babeddb87ba941a28757ee1776487483","0294ab6440cb471d8e59fd4dc2fa480c","75e69d8c60194ce0bff6e0279c813264","b99d98966ea14fc68e35a80bd6ccae5d","4dd6addcb8fb4780ba3a7e5805f92559","ff58658c441441b788d3a251bbf6dadb","17f5f237e9584a529405d393e23a5f20"]},"id":"ZRV0qSrxOIIq","executionInfo":{"status":"ok","timestamp":1747051057329,"user_tz":-180,"elapsed":46,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"c2b8d801-8b45-4ae4-867c-d62b3c6ceb3f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Textarea(value='Paste your LinkedIn post here...', description='Post:', layout=Layout(height='250px', width='1‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8fbcbdc4604d2fbdd66f01911ba41e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(button_style='primary', description='Analyze Post', style=ButtonStyle(), tooltip='Click to analyze the ‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75e69d8c60194ce0bff6e0279c813264"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff58658c441441b788d3a251bbf6dadb"}},"metadata":{}}]},{"cell_type":"code","source":["def analyze_linkedin_post(post_text: str) -> dict:\n","    system_prompt = (\n","        \"You are a professional content analyst with expertise in business information security, data governance, and records management. \"\n","        \"Your task is to analyze a LinkedIn post relevant to this field and provide:\\n\\n\"\n","        \"1. Engagement: Is the post likely to attract attention within professional circles? Does it prompt reactions, comments, or shares?\\n\"\n","        \"2. User-value: What value does it provide to professionals in information security, compliance, digital archiving, or document lifecycle management?\\n\"\n","        \"3. Suggestions: What could improve its impact ‚Äî such as clarity, authority, call to action, or format?\\n\\n\"\n","        \"Respond in a JSON format with three keys: 'engagement', 'user_value', and 'suggestions'.\"\n","    )\n","\n","    user_prompt = f\"LinkedIn post:\\n\\\"\\\"\\\"\\n{post_text}\\n\\\"\\\"\\\"\"\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt},\n","            {\"role\": \"user\", \"content\": user_prompt}\n","        ],\n","        temperature=0.3,\n","    )\n","\n","    import json\n","    reply = response.choices[0].message.content\n","    try:\n","        return json.loads(reply)\n","    except json.JSONDecodeError:\n","        return {\"raw\": reply}\n"],"metadata":{"id":"ItOrmJRmX6YX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qIpEYIl4YJcW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","\n","# Create widgets\n","post_input = widgets.Textarea(\n","    value='Paste your LinkedIn post here...',\n","    placeholder='Paste your LinkedIn post here...',\n","    description='Post:',\n","    layout=widgets.Layout(width='100%', height='250px')\n",")\n","\n","analyze_button = widgets.Button(\n","    description='Analyze Post',\n","    button_style='primary',\n","    tooltip='Click to analyze the LinkedIn post'\n",")\n","\n","output = widgets.Output()\n","\n","# Define behavior on click\n","def on_analyze_clicked(b):\n","    with output:\n","        clear_output()\n","        print(\"üîé Analyzing LinkedIn Post...\\n\")\n","\n","        raw_post = post_input.value\n","        post_data = preprocess_linkedin_post(raw_post)\n","\n","        print(\"=== üõ†Ô∏è Preprocessing ===\")\n","        print(f\"‚Ä¢ Words: {post_data['word_count']}\")\n","        print(f\"‚Ä¢ Characters: {post_data['char_count']}\")\n","        print(f\"‚Ä¢ Length Feedback: {post_data['notes']['length_comment']}\")\n","        print(f\"‚Ä¢ Grammar: {post_data['notes']['corrections_applied']}\\n\")\n","\n","        print(\"=== üßπ Cleaned Post (Corrected) ===\")\n","        print(post_data['corrected'])\n","\n","        print(\"\\n=== ü§ñ GPT Analysis ===\")\n","        result = analyze_linkedin_post(post_data[\"corrected\"])\n","        if \"raw\" in result:\n","            print(result[\"raw\"])\n","        else:\n","            print(f\"‚Ä¢ Engagement: {result['engagement']}\")\n","            print(f\"‚Ä¢ User Value: {result['user_value']}\")\n","            print(f\"‚Ä¢ Suggestions: {result['suggestions']}\")\n","\n","# Connect button to function\n","analyze_button.on_click(on_analyze_clicked)\n","\n","# Display interface\n","display(post_input, analyze_button, output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323,"referenced_widgets":["98dd61aa34d042518efbd153fa454a45","3de6419aa20d4d0893573800bbddedb9","874ee1947c49491e93986cee1c301876","c1f17765eb4543ac93cf3c75a5dc95a3","fc1ca417b155429f8f9d03d7285c829e","8a6e43ea0128460296b62cef92d0246a","df28f61a9f364757bd225566f84c874c","72c6853573734c498c40f9bd14a19475"]},"executionInfo":{"status":"ok","timestamp":1747051858754,"user_tz":-180,"elapsed":35,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"06fabff0-e4e4-4b4d-9c8d-da08f5a0e594","id":"c79bX6FAYK4e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Textarea(value='Paste your LinkedIn post here...', description='Post:', layout=Layout(height='250px', width='1‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98dd61aa34d042518efbd153fa454a45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(button_style='primary', description='Analyze Post', style=ButtonStyle(), tooltip='Click to analyze the ‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f17765eb4543ac93cf3c75a5dc95a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df28f61a9f364757bd225566f84c874c"}},"metadata":{}}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"p6lwhSURYgsB","executionInfo":{"status":"error","timestamp":1747051486555,"user_tz":-180,"elapsed":746,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"07adece1-034a-4a13-efa5-2059efb004b9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-fb9abc2ecf15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"dlg1DrvAYpzA","executionInfo":{"status":"error","timestamp":1747051521507,"user_tz":-180,"elapsed":44,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"9ed1fe68-66a9-43f1-958a-247b02370ef3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OpenAIError","evalue":"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-28964e84bb3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             )\n","\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"]}]},{"cell_type":"code","source":["from getpass import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîê Enter your OpenAI API key: \").strip()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vj-ncKVOY1t2","executionInfo":{"status":"ok","timestamp":1747051582137,"user_tz":-180,"elapsed":11510,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"b71c5284-f4ad-4094-f711-68737c57e277"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["üîê Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"],"metadata":{"id":"IyQB044aY7yI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n"],"metadata":{"id":"JkWjN8HbYnlB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","\n","# Create widgets\n","post_input = widgets.Textarea(\n","    value='Paste your LinkedIn post here...',\n","    placeholder='Paste your LinkedIn post here...',\n","    description='Post:',\n","    layout=widgets.Layout(width='100%', height='250px')\n",")\n","\n","analyze_button = widgets.Button(\n","    description='Analyze Post',\n","    button_style='primary',\n","    tooltip='Click to analyze the LinkedIn post'\n",")\n","\n","output = widgets.Output()\n","\n","# Define behavior on click\n","def on_analyze_clicked(b):\n","    with output:\n","        clear_output()\n","        print(\"üîé Analyzing LinkedIn Post...\\n\")\n","\n","        raw_post = post_input.value\n","        post_data = preprocess_linkedin_post(raw_post)\n","\n","        print(\"=== üõ†Ô∏è Preprocessing ===\")\n","        print(f\"‚Ä¢ Words: {post_data['word_count']}\")\n","        print(f\"‚Ä¢ Characters: {post_data['char_count']}\")\n","        print(f\"‚Ä¢ Length Feedback: {post_data['notes']['length_comment']}\")\n","        print(f\"‚Ä¢ Grammar: {post_data['notes']['corrections_applied']}\\n\")\n","\n","        print(\"=== üßπ Cleaned Post (Corrected) ===\")\n","        print(post_data['corrected'])\n","\n","        print(\"\\n=== ü§ñ GPT Analysis ===\")\n","        result = analyze_linkedin_post(post_data[\"corrected\"])\n","        if \"raw\" in result:\n","            print(result[\"raw\"])\n","        else:\n","            print(f\"‚Ä¢ Engagement: {result['engagement']}\")\n","            print(f\"‚Ä¢ User Value: {result['user_value']}\")\n","            print(f\"‚Ä¢ Suggestions: {result['suggestions']}\")\n","\n","# Connect button to function\n","analyze_button.on_click(on_analyze_clicked)\n","\n","# Display interface\n","display(post_input, analyze_button, output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":673,"referenced_widgets":["6ac48c68e30c4548b1599da865af320a","799902f4933d42b6bed9b17f770eab41","e551071b132143e38e96bbaf4a239da0","b28edbb745cc464096bd256335ef1cb9","37f40f5241a54d0da42b096583a1b7b5","92c827b98469441bb22835ceb4d343df","635e36cb13d14e54b5238cd5d9fa777c","b3df0dc1eebe404ea4c6b8f1c7b1c71f"]},"id":"5i7VMRM4aCyw","executionInfo":{"status":"ok","timestamp":1747068082181,"user_tz":-180,"elapsed":63,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}},"outputId":"bcb62f8c-3e3c-4e8e-9c86-e95d0a0db0b6"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Textarea(value='Paste your LinkedIn post here...', description='Post:', layout=Layout(height='250px', width='1‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac48c68e30c4548b1599da865af320a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(button_style='primary', description='Analyze Post', style=ButtonStyle(), tooltip='Click to analyze the ‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28edbb745cc464096bd256335ef1cb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"635e36cb13d14e54b5238cd5d9fa777c"}},"metadata":{}}]},{"cell_type":"code","source":["def preprocess_linkedin_post(raw_post: str) -> dict:\n","    import re\n","    paragraphs = [p.strip() for p in raw_post.strip().split('\\n') if p.strip()]\n","    formatted = \"\\n\\n\".join(paragraphs)\n","    formatted = re.sub(r\"[-‚Ä¢‚û§‚óæ‚ñ™]+ ?\", \"‚Ä¢ \", formatted)\n","    formatted = re.sub(r'\\bhashtag#', '#', formatted)\n","\n","    word_count = len(formatted.split())\n","    char_count = len(formatted)\n","\n","    if word_count < 30:\n","        length_comment = \"Too short ‚Äî consider expanding the post for impact.\"\n","    elif word_count > 300:\n","        length_comment = \"Too long ‚Äî may reduce engagement. Consider trimming.\"\n","    else:\n","        length_comment = \"Length is appropriate.\"\n","\n","    corrected = correct_grammar_with_gpt(formatted)\n","    correction_comment = \"Grammar corrected using GPT.\"\n","\n","    return {\n","        \"formatted\": formatted,\n","        \"corrected\": corrected,\n","        \"word_count\": word_count,\n","        \"char_count\": char_count,\n","        \"notes\": {\n","            \"length_comment\": length_comment,\n","            \"corrections_applied\": correction_comment\n","        }\n","    }\n"],"metadata":{"id":"4O0FI_2tXhTi","executionInfo":{"status":"ok","timestamp":1747068003613,"user_tz":-180,"elapsed":1,"user":{"displayName":"Agne Jurciukonyte","userId":"02313198670497506058"}}},"execution_count":2,"outputs":[]}]}